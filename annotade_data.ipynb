{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VNN forum dataset has been:\n",
    "* cleand from url\n",
    "* chunked into max token lengt 256 using tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "* embeddings were calculated using model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "* labeled with zeroshot classification (classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\"))\n",
    "\n",
    "Text chunks with top scores from zeroshot classification were assesed manually till 100 positive and 100 negative labels were identified. \\\n",
    "\n",
    "Hypothesis for labeling is \"this text is racist\". \\\n",
    "*Racism is based on the idea that there are different human races. For the current example only hatered white people vs people of colour is considered (thus exluding for example antisemitism)*\n",
    "\n",
    "In the following notebook df is divided into df_labeled and df_unlabeled (remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to make the text wrap in dataframes and display all rows\n",
    "# pd.set_option('display.max_colwidth', None)  # Set to None to allow text to wrap\n",
    "# pd.set_option('display.expand_frame_repr', False)  # Prevent the DataFrame from expanding to the available width\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = '/home/dorota/projects/python/investigations/dorota_lia/active_learning/active_learning.ipynb' #TODO remove when working from .py as __file__ is defined in .py but not .ipunb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12515, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(Path(__file__).parent / 'data/df_10k_chunked_zeroshot_racism.tsv',  sep = '\\t')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of manually annotated indexes with 1 (racist) and 0 (not racist)\n",
    "idx_1 = [3, 5, 8, 9, 11, 13, 15, 17, 18, 19, 22, 24, 25, 26, 27, 28, 31, 32, 36, 37, 41, 43, 44, 46, 47, 48, 50, 51, \n",
    "52, 53, 54, 56, 57, 60, 61, 62, 65, 66, 68, 72, 73, 76, 79, 80, 81, 83, 84, 85, 88, 93, 97, 103, 105, 106, 109, 111, 114, 115, 116, 117, 118, 119, 120, 123, 124, 126, \n",
    "127, 130, 131, 133, 134, 135, 140, 141, 142, 143, 144, 148, 149, 152, 153, 154, 155, 156, 164, 165, 166, 174, 176, 182, 183, 184, 186, 187, 189, 190, 191, 192, 203, 214]\n",
    "idx_0 = [4, 12, 14, 16, 20, 30, 35, 49, 55, 63, 64, 78, 91, 95, 96, 99, 112, 113, 138, 150, 169, 172, 175, 291, 299, 2007, 2018, 2038, 2043, 2044, 2047, 2049, 2052, 2061, 2063, 2067, 2077, 2078, 2084, 2089, \n",
    "2091, 2093, 2099, 2101, 2105, 2112, 2114, 2117, 2126, 2127, 2130, 2804, 2813, 2815, 2816, 2829, 2834, 2859, 2879, 2882, 2886, 2891, 2907, 2945, 2949, \n",
    "2957, 2960, 2967, 2980, 2981, 2988, 2990, 2993, 2996, 3501, 3523, 3530, 3532, 3534, 3540, 3542, 3562, 3563, 3565, 3566, 3568, 3569, 3574, 5000, 5001, 5002, 5003, 9000, 9001, 9007, 9009, 9012, 9014, 9017, 9191 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine indexes to one sorted list\n",
    "idx_labeled = list(idx_1 + idx_0)\n",
    "idx_labeled.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with labeled rows...\n",
    "df_labeled = df.loc[idx_labeled]\n",
    "df_labeled.loc[idx_1, 'racist_text'] = 1\n",
    "df_labeled.loc[idx_0, 'racist_text'] = 0\n",
    "df_labeled['racist_text'] = df_labeled['racist_text'].astype(int)\n",
    "print(df_labeled.shape)\n",
    "df_labeled.iloc[:, [0, 10, 11]  + list(range(13, len(df_labeled.columns)))].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and a dataframe with ramaining unlabeled rows\n",
    "df_unlabeled = df[~df.index.isin(df_labeled.index)]\n",
    "print(df_unlabeled.shape)\n",
    "df_unlabeled.iloc[:, [0, 10, 11]  + list(range(13, len(df_unlabeled.columns)))].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.to_csv(Path(__file__).parent / 'data/df_labeled_racism.tsv', sep='\\t', index=True)\n",
    "df_unlabeled.to_csv(Path(__file__).parent / 'data/df_unlabeled_racism.tsv', sep='\\t', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
