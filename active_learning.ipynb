{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "Active learning is used to annotate data. Inital annotated data is 200 datapoints from annotate.ipynb plus any which have been unnotated in earlier runs. Annotated data is split into train data to fit initial learner and test data to evalate accurac score for each iteration. Analysis is done in 384 dimensions, while visualization in 3.\n",
    "Basic ActiveLearner is initialized with estimators: LogisticRegression or RandomForrest and uncertaquery strategy as query strategy.\n",
    "Most uncertain points are queried and new accuracy score calculated a predefined number of times.\n",
    "Query results are saved together with plots and model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "from IPython.display import display, HTML # Jupyter Notebook specific\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Alt 1). Read in data where annotaions from all runs are gathered together enabling larger test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in labeled data from all tsv files in folder\n",
    "data_folder = Path('/mnt/c/Yose/Data/vnn_data/active_learning/')\n",
    "pattern = 'df_labeled_racism*.tsv'\n",
    "\n",
    "filepaths = data_folder.glob(pattern) # find all files matching the pattern in the data folder\n",
    "\n",
    "df_labeled = pd.DataFrame()\n",
    "\n",
    "for filepath in filepaths:\n",
    "    df = pd.read_csv(filepath, sep='\\t', index_col=0)\n",
    "    df_labeled = pd.concat([df_labeled, df], ignore_index=False)\n",
    "\n",
    "df_labeled = df_labeled[~df_labeled.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in unlabeled data and remove indexes present in labeled data\n",
    "df_unlabeled = pd.read_csv(data_folder / 'df_unlabeled_racism.tsv',  sep = '\\t', index_col=0 ) # unlabeled data\n",
    "df_unlabeled = df_unlabeled[~df_unlabeled.index.isin(df_labeled.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Alt 2). ... or read in original data with 200 annotated poits...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_labeled = pd.read_csv(data_folder / 'df_labeled_racism.tsv',  sep = '\\t', index_col=0 ) # manually labeled data\n",
    "# df_unlabeled = pd.read_csv(data_folder / 'df_unlabeled_racism.tsv',  sep = '\\t', index_col=0 ) # unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlabeled data\n",
    "* 'unlabeled' to fit to model and choose the most uncertain after each itteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlabeled = df_unlabeled['chunk_embedding']\n",
    "X_unlabeled = X_unlabeled.apply(lambda x: np.fromstring(x[1:-1], sep=' ')).tolist() # transform X_labeled from str of embeddings to np array\n",
    "X_unlabeled = np.array(X_unlabeled)\n",
    "X_unlabeled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeled data:\n",
    "* 'train' for initial model fitting\n",
    "* 'test' for continous evaluatin of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labeled, y_labeled = df_labeled['chunk_embedding'], df_labeled['racist_text']\n",
    "X_labeled = X_labeled.apply(lambda x: np.fromstring(x[1:-1], sep=' ')).tolist() # transform X_labeled from str of embeddings to np array\n",
    "X_labeled = np.array(X_labeled)\n",
    "y_labeled = np.array(y_labeled) # learner.teach(X, y) requires array and not pd Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Alt1). Use random train_test split...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.75, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Alt2). ...or if want to start with 2 train datapoints choose those manually since need 1 from each category. Remaining labeled 198 are use as test data.\\\n",
    "(Based on original labeled data of 200 points where first is 1 and last is 0.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array([X_labeled[0], X_labeled[-1]])\n",
    "# y_train = np.array([y_labeled[0], y_labeled[-1]])\n",
    "# X_test = X_labeled[1:-1]\n",
    "# y_test = y_labeled[1:-1]\n",
    "\n",
    "# X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimenstions for visualization and add to dataframes\n",
    "umap_params = {\n",
    "    'n_neighbors':20,\n",
    "    'n_components':3,\n",
    "    'min_dist':0.05, \n",
    "    'metric':'cosine'\n",
    "}\n",
    "\n",
    "umap = UMAP(**umap_params)\n",
    "X_labeled_umap = umap.fit_transform(X_labeled)\n",
    "X_unlabeled_umap = umap.transform(X_unlabeled)\n",
    "\n",
    "\n",
    "df_labeled['umap_x'], df_labeled['umap_y'], df_labeled['umap_z'] = X_labeled_umap.T\n",
    "df_unlabeled['umap_x'], df_unlabeled['umap_y'], df_unlabeled['umap_z'] = X_unlabeled_umap.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common plotting parameters\n",
    "\n",
    "plotting_params_labeled = {\n",
    "    'x':\"umap_x\",\n",
    "    'y':\"umap_y\",\n",
    "    'z':\"umap_z\",\n",
    "    'color':\"racist_text\",\n",
    "    'width':1000,\n",
    "    'height':700,\n",
    "}\n",
    "\n",
    "plotting_params_unlabeled = {\n",
    "    'x': \"umap_x\",\n",
    "    'y': \"umap_y\",\n",
    "    'z': \"umap_z\",\n",
    "}\n",
    "\n",
    "hover_data_common = {\"umap_x\": False, \"umap_y\": False, \"umap_z\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = px.scatter_3d(\n",
    "    df_labeled,\n",
    "    **plotting_params_labeled,\n",
    "    title=\"Annotated embeddings with hypotesis 'This text is racist' (1-yes, 0-no) and datapoints to label (gray)\",\n",
    "    hover_data={\"index\": df_labeled.index, **hover_data_common},\n",
    ")\n",
    "\n",
    "unlabaled_scatter = px.scatter_3d(\n",
    "    df_unlabeled,\n",
    "    **plotting_params_unlabeled,\n",
    "    hover_data={\"index\": df_unlabeled.index, **hover_data_common},\n",
    ")\n",
    "unlabaled_scatter.update_traces(marker=dict(color='gray', size = 2), text = 'unlabeled', hovertemplate='Unlabeled')\n",
    "fig1.add_trace(unlabaled_scatter.data[0])\n",
    "\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression(penalty = 'l2', solver='saga', max_iter=10000, C=0.1)\n",
    "# estimator = RandomForestClassifier(n_estimators=150, max_depth=3)\n",
    "\n",
    "query_strategy = uncertainty_sampling\n",
    "\n",
    "learner = ActiveLearner(\n",
    "    estimator=estimator,\n",
    "    query_strategy=query_strategy,\n",
    "    X_training=X_train, y_training=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize classification prior to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled['y_pred'] = learner.predict(X_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = px.scatter_3d(\n",
    "    df_labeled,\n",
    "    **plotting_params_labeled,\n",
    "    title=\"Annotated embeddings with hypotesis 'This text is racist' and predicted classification prior to training\",\n",
    "    hover_data={\"index\": df_labeled.index, **hover_data_common},\n",
    ")\n",
    "\n",
    "unlabaled_scatter = px.scatter_3d(\n",
    "    df_unlabeled,\n",
    "    **plotting_params_unlabeled,\n",
    "    color='y_pred',\n",
    "    hover_data={\"index\": df_unlabeled.index, **hover_data_common},\n",
    ")\n",
    "unlabaled_scatter.update_traces(marker=dict(size = 2, line=dict(width=0.5, color='DarkSlateGrey')))\n",
    "fig2.add_trace(unlabaled_scatter.data[0])\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label data interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_queries = 10\n",
    "\n",
    "# keep track of scores using test data\n",
    "initial_score = [learner.score(X_test, y_test)][0]\n",
    "print(f\"Initial score is: {initial_score}\")\n",
    "accuracy_scores = [initial_score]\n",
    "\n",
    "df_labeled_in_learning = pd.DataFrame(columns=df_labeled.columns)  # new df to save chunks labeled during active learning\n",
    "X_unlabeled_idx = np.array(range(len(df_unlabeled)))  # for mapping of indexes between X_unlabeled and df_unlabeled\n",
    "\n",
    "pd.set_option('max_colwidth', None)  # for visualization of text_chunk in Jupyter Notebook\n",
    "\n",
    "for i in range(n_queries):\n",
    "    query_index, query_instance = learner.query(X_unlabeled)  # positional index in array\n",
    "    \n",
    "    text_chunk_for_labeling = df_unlabeled.iloc[X_unlabeled_idx[query_index]]['text_chunk'] #get corresponding text_chunk\n",
    "    print(text_chunk_for_labeling, end=\"\\r\", flush=True)\n",
    "\n",
    "    # label query\n",
    "    while True:\n",
    "        try:\n",
    "            y_new = int(input(\"Enter 1 or 0 for text_chunk: \"))\n",
    "            if y_new in [0, 1]:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter 0 or 1.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter 0 or 1.\")\n",
    "\n",
    "    learner.teach(query_instance.reshape(1, -1), np.array([y_new], dtype=int)) # fit with train and new labels\n",
    "    print(f'Annotated label: {y_new}')\n",
    "\n",
    "    # Create a new DataFrame with the current data point\n",
    "    df_new_row = df_unlabeled.iloc[X_unlabeled_idx[query_index]].copy()\n",
    "    df_new_row['racist_text'] = y_new\n",
    "    df_labeled_in_learning = pd.concat([df_labeled_in_learning, df_new_row], ignore_index=False)  # want to keep original df_unlabeled indexes\n",
    "\n",
    "    # remove query point from unlabeled array\n",
    "    X_unlabeled, X_unlabeled_idx = np.delete(X_unlabeled, query_index, axis=0), np.delete(X_unlabeled_idx, query_index, axis=0)\n",
    "\n",
    "    accuracy_scores.append(learner.score(X_test, y_test))\n",
    "    print(f'Current accuracy score: {learner.score(X_test, y_test)}')\n",
    "    print('=' * 300)\n",
    "\n",
    "df_labeled_in_learning['racist_text'] = df_labeled_in_learning['racist_text'].astype(np.int64)  # to match all other scores which are np\n",
    "\n",
    "pd.reset_option('max_colwidth') # for visualization of text_chunk in Jupyter Notebook\n",
    "\n",
    "print('=' * 300)\n",
    "print(accuracy_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_unlabeled = df_unlabeled[~df_unlabeled.index.isin(df_labeled_in_learning.index)] # temp unlabeled dff to be able to re-plot data prior to active learning from df\n",
    "dff_unlabeled['y_pred'] = learner.predict(X_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = px.scatter_3d(\n",
    "    df_labeled,\n",
    "    **plotting_params_labeled,\n",
    "    title=\"Annotated embeddings with hypotesis 'This text is racist' and predicted classification after training\",\n",
    "    hover_data={\"index\": df_labeled.index, **hover_data_common},\n",
    ")\n",
    "\n",
    "labeled_in_learning_scatter = px.scatter_3d(\n",
    "    df_labeled_in_learning,\n",
    "    **plotting_params_labeled,\n",
    "    hover_data={\"index\": df_labeled_in_learning.index, **hover_data_common},\n",
    ")\n",
    "fig3.add_trace(labeled_in_learning_scatter.data[0])\n",
    "\n",
    "\n",
    "unlabaled_scatter = px.scatter_3d(\n",
    "    dff_unlabeled,\n",
    "    **plotting_params_unlabeled,\n",
    "    color='y_pred',\n",
    "    hover_data={\"index\": dff_unlabeled.index, **hover_data_common},\n",
    ")\n",
    "unlabaled_scatter.update_traces(marker=dict(size = 2, line=dict(width=0.5, color='DarkSlateGrey')))\n",
    "fig3.add_trace(unlabaled_scatter.data[0])\n",
    "\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4 = px.line(y=accuracy_scores, title='Incremental classification accuracy', width=700, height=500, markers=True, labels={\n",
    "                     \"x\": \"Query iteration\",\n",
    "                     \"y\": \"Classification accuracy\"})\n",
    "fig4.update_yaxes(range=[0, 1])\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data, plots and model from active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define counter for df_labeled_in_learning and apply the same counter for all other data to be saved from the same run\n",
    "# save data\n",
    "filename_df = \"df_labeled_racism_in_learning\"\n",
    "counter = 1\n",
    "output_filepath_df = data_folder / f\"{filename_df}_{counter}.tsv\"\n",
    "\n",
    "while output_filepath_df.exists():\n",
    "    counter += 1\n",
    "    output_filepath_df = data_folder / f\"{filename_df}_{counter}.tsv\"\n",
    "\n",
    "df_labeled_in_learning = df_labeled_in_learning.drop(['umap_x', 'umap_y', 'umap_z', 'y_pred'], axis=1)\n",
    "df_labeled_in_learning.to_csv(output_filepath_df, sep='\\t', index=True)\n",
    "\n",
    "filename_scores = \"accuracy_scores\"\n",
    "output_filepath_scores = data_folder / f\"{filename_scores}_{counter}.tsv\"\n",
    "df_accuracy_scores = pd.DataFrame({'accuracy_score': accuracy_scores})\n",
    "df_accuracy_scores.to_csv(output_filepath_scores, sep='\\t', index=False)\n",
    "\n",
    "# save plots\n",
    "filename_fig2 = \"classification_before_training\"\n",
    "output_filepath_fig2 = data_folder / f\"{filename_fig2}_{counter}.html\"\n",
    "fig2.write_html(output_filepath_fig2)\n",
    "\n",
    "filename_fig3 = \"classification_after_training\"\n",
    "output_filepath_fig3 = data_folder / f\"{filename_fig3}_{counter}.html\"\n",
    "fig3.write_html(output_filepath_fig3)\n",
    "\n",
    "filename_fig4 = \"accracy_scores\"\n",
    "output_filepath_fig4 = data_folder / f\"{filename_fig4}_{counter}.html\"\n",
    "fig4.write_html(output_filepath_fig4)\n",
    "\n",
    "# save model (learner) after training\n",
    "filename_learner = \"model_active_learner\"\n",
    "output_filepath_learner = data_folder / f\"{filename_learner}_{counter}.pkl\"\n",
    "joblib.dump(learner, output_filepath_learner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
